<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Papers about Dynamic Gaussian Splatting | LONGAN BLOG</title><meta name="author" content="Wang Longan,wanglongan1007@gmail.com"><meta name="copyright" content="Wang Longan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction 18 Mar 2024  Abstract3D Gaussian Splatting (3DGS) has become an emerging tool for dynamic scene reconstruction. However, e">
<meta property="og:type" content="article">
<meta property="og:title" content="Papers about Dynamic Gaussian Splatting">
<meta property="og:url" content="https://dianlisan.github.io/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/index.html">
<meta property="og:site_name" content="LONGAN BLOG">
<meta property="og:description" content="Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction 18 Mar 2024  Abstract3D Gaussian Splatting (3DGS) has become an emerging tool for dynamic scene reconstruction. However, e">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://dianlisan.github.io/img/self.jpg">
<meta property="article:published_time" content="2024-06-24T08:03:34.000Z">
<meta property="article:modified_time" content="2024-06-25T05:42:44.376Z">
<meta property="article:author" content="Wang Longan">
<meta property="article:tag" content="Papers">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://dianlisan.github.io/img/self.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://dianlisan.github.io/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Papers about Dynamic Gaussian Splatting',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-25 13:42:44'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/self.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347)"><nav id="nav"><span id="blog-info"><a href="/" title="LONGAN BLOG"><span class="site-name">LONGAN BLOG</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Papers about Dynamic Gaussian Splatting</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-06-24T08:03:34.000Z" title="Created 2024-06-24 16:03:34">2024-06-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-06-25T05:42:44.376Z" title="Updated 2024-06-25 13:42:44">2024-06-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Dynamic-Gaussian-Splatting/">Dynamic Gaussian Splatting</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Motion-aware-3D-Gaussian-Splatting-for-Efficient-Dynamic-Scene-Reconstruction"><a href="#Motion-aware-3D-Gaussian-Splatting-for-Efficient-Dynamic-Scene-Reconstruction" class="headerlink" title="Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.11447">Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction</a></h1><ul>
<li>18 Mar 2024</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>3D Gaussian Splatting (3DGS) has become an emerging tool for dynamic scene reconstruction. However, existing methods focus mainly on extending static 3DGS into a time-variant representation, <span style="color: red;"><strong>while overlooking the rich motion information carried by 2D observations</strong></span>, thus suffering from performance degradation and model redundancy. To address the above problem, we propose a novel <span style="color: blue;"><strong>motion-aware</strong></span> enhancement framework for dynamic scene reconstruction, which mines useful motion cues from optical flow to improve different paradigms of dynamic 3DGS.</p>
<ul>
<li>Specifically, we first establish a <strong>correspondence between 3D Gaussian movements and pixel-level flow</strong>.</li>
<li>Then a novel <strong>flow augmentation</strong> method is introduced with additional insights into <strong>uncertainty</strong> and <strong>loss collaboration</strong>.</li>
<li>Moreover, for the prevalent <strong>deformation-based</strong> paradigm that presents a harder optimization problem, a <strong>transient-aware deformation auxiliary module is proposed</strong>. </li>
<li>We conduct extensive experiments on both multi-view and monocular scenes to verify the merits of our work. Compared with the baselines, our method shows significant superiority in both rendering quality and efficiency.</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>While static scene modeling has witnessed significant progress in recent years, <strong>reconstructing dynamic scenes</strong> remains an intractable challenge due to the difficulties introduced by <span style="color: red;"><strong>motion complexities, topological changes, and spatially or temporally sparse observations</strong></span>.</p>
<p>In the past few years, <strong>Neural Radiance Fields</strong> (NeRF) has emerged as a remarkable implicit representation for 3D scenes. Despite their impressive visual quality, <span style="color: red;"><strong>the large time overhead stands as a non-negligible obstacle to their practical application</strong></span>. Recently, a new method named <strong>3D Gaussian Splatting</strong> (3DGS) has attracted substantial attention from the research community. 3DGS gets rid of the expensive deep neural networks and ray-tracing rendering of NeRF-based methods by introducing the explicit 3D Gaussian representation and efficient point-based rasterization. As a strong competitor to NeRF, 3DGS achieves comparable performance in novel view synthesis while <span style="color: blue;"> <strong>boosting the rendering speed to a real-time level</strong> </span>.</p>
<p><strong>It is then a straightforward but challenging task to extend the static 3DGS to a time-variant representation for dynamic content.</strong> Some pioneers have tried different strategies, e.g., <strong>iteration</strong> or <strong>deformation</strong>, to address this problem. However, these 3DGS-based works typically focus on the design of dynamic modeling. They regard frames as discrete samples to fit time-dependent trajectories or deformations, <span style = "color: red;"><strong>while overlooking the rich motion cues underneath sequential 2D observations</strong></span>. Since dynamic 3DGS involves explicit moving and deforming of Gaussians, it presents a tough <span style = "color: red;"><strong>under-constrained problem</strong></span> to use only images to supervise the reconstruction. <strong>The model is prone to local optimum where temporal consistency of Gaussians is not maintained as in physical world, especially for cases with insufficient viewpoints.</strong> This leads to visual overfitting, performance degradation, and redundant modeling in practice.</p>
<p><strong>To address the above issues, we propose a novel motion-aware framework to enhance dynamic 3DGS by taking full advantage of optical flow prior.</strong> </p>
<ul>
<li>As a well-explored representation of pixel-level movement, <span style = "color: blue;"><strong>optical flow can be efficiently predicted by pretrained networks</strong></span>, providing low-cost 2D motion prior for 3DGS. </li>
<li>Instead of using plausible render-based supervision like previous practices in depth or segmentation, we propose to establish a more robust and finer-grained cross-dimensional motion correspondence specially designed for flows. In this way, <span style = "color: blue;"><strong>Gaussian motions between frames can be aligned with 2D prior using our uncertainty-aware flow loss</strong>.</span></li>
<li>Meanwhile, We offer <span style = "color: blue;"> <strong>dynamic awareness to existing regularization in neural rendering with the help of flow prior</strong></span>, thereby giving special attention to the motion parts during optimization.</li>
<li>Moreover, the prevalent deformation-based paradigm for dynamic 3DGS is susceptible to 3D motion ambiguities when relying solely on relative flow constraints. Therefore, we propose an additional <span style = "color: blue;"> <strong>deformation auxiliary module to inject transient motion information into Gaussian features and improve the dynamic modeling</strong></span>.</li>
<li>The overall framework is proved by extensive experiments to be an effective enhancing solution for multi-view/monocular scenes, which possesses efficient dynamic modeling capabilities with less redundancy.</li>
</ul>
<h1 id="4D-Gaussian-Splatting-Towards-Efficient-Novel-View-Synthesis-for-Dynamic-Scenes"><a href="#4D-Gaussian-Splatting-Towards-Efficient-Novel-View-Synthesis-for-Dynamic-Scenes" class="headerlink" title="4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.03307">4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes</a></h1><ul>
<li>7 Feb 2024</li>
</ul>
<h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><p>We consider the problem of novel view synthesis (NVS) for dynamic scenes. Recent neural approaches have accomplished exceptional NVS results for static 3D scenes, but extensions to 4D time-varying scenes remain non-trivial. <span style = "color: red;"><strong>Prior efforts often encode dynamics by learning a canonical space plus implicit or explicit deformation fields, which struggle in challenging scenarios like sudden movements or capturing high-fidelity renderings.</strong></span> In this paper, we introduce 4D Gaussian Splatting (4DGS), a novel method that represents dynamic scenes with <span style = "color:blue"><strong>anisotropic 4D XY ZT Gaussians</strong> </span>, inspired by the success of 3D Gaussian Splatting in static scenes [26]. </p>
<ul>
<li>We model dynamics at each timestamp by temporally <strong>slicing</strong> the 4D Gaussians, which naturally compose dynamic 3D Gaussians and can be seamlessly projected into images. </li>
<li>As an explicit spatialtemporal representation, 4DGS demonstrates powerful capabilities for modeling complicated dynamics and fine details—especially for scenes with abrupt motions. </li>
<li>We further implement our temporal slicing and splatting techniques in a highly optimized CUDA acceleration framework, achieving real-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and 583 FPS on an RTX 4090 GPU. </li>
<li>Rigorous evaluations on scenes with diverse motions showcase the superior efficiency and effectiveness of 4DGS, which consistently outperforms existing methods both quantitatively and qualitatively.</li>
</ul>
<h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>Reconstructing 3D scenes from 2D images and synthesizing their appearance from novel views has been a longstanding goal in computer vision and graphics. This task is pivotal in numerous industrial applications including film, gaming, and VR/AR, where there is a substantial demand for high-speed, photo-realistic rendering effects. The task diverges into two different scene types: <strong>static</strong> scenes where objects are still across all images [4, 24, 27, 37] and <strong>dynamic</strong> scenes where scene contents exhibit temporal variations [11, 33, 40, 43, 57]. While the former has witnessed significant progress recently, <span style = "color: red;"><strong>efficient and accurate NVS for dynamic scenes remains challenging due to the complexities introduced by the temporal dimension and diverse motion patterns</strong></span>. </p>
<p>A variety of methods have been proposed to tackle the challenges posed by dynamic NVS. </p>
<ul>
<li>A series of methods model the 3D scene and its dynamics jointly. <span style = "color: red;"><strong>However, these methods often fall short in preserving fine details in the NVS renderings due to the complexity caused by the highly entangled spatial and temporal dimensions.</strong></span></li>
<li>Alternatively, many existing techniques decouple dynamic scenes by learning a static canonical space and then predicting a deformation field to account for the temporal variations. <span style = "color: red;"><strong>Nonetheless, this paradigm struggles in capturing complex dynamics such as objects appearing or disappearing suddenly.</strong></span> </li>
<li>More importantly, prevailing methods on dynamic NVS mostly build upon volumetric rendering, which requires dense sampling on millions of rays. <span style = "color: red;"><strong>As a consequence, these methods typically cannot supportreal-time rendering speed even for static scenes.</strong></span> </li>
</ul>
<p>Recently, <strong>3D Gaussian Splatting (3DGS)</strong>  has emerged as a powerful tool for efficient NVS of static scenes. By explicitly modeling the scene with 3D Gaussian ellipsoids and employing fast rasterization technique, it achieves photo-realistic NVS in real time. <span style = "color: blue;"><strong>Inspired by this, we propose to lift Gaussians from 3D to 4D and provide a novel spatial-temporal representation that enables NVS for more challenging dynamic scenes</strong></span>. </p>
<p><span style = "color: blue;"> <strong>Our key observation is that 3D scene dynamics at each timestamp can be viewed as 4D spatial-temporal Gaussian ellipsoids sliced with different time queries.</strong></span> The dynamics in 2D XY space at time $T_i$ is equivalent to building 3D XYT Gaussians and slicing by the $t = T_i$ plane. Analogously, we extend 3D Gaussians to 4D XYZT space to model dynamic 3D scenes. The temporally sliced 4D Gaussians compose 3D Gaussians that can be seamlessly projected to 2D screens via fast rasterization, inheriting both exquisite rendering effects and high speed characteristic from 3DGS. Moreover, extending the prune-split mechanism in the temporal dimension makes 4D Gaussians particularly suitable for <strong>representing complex dynamics, including abrupt appearances or disappearances</strong>.</p>
<p>It is non-trivial to lift 3D Gaussians into 4D space, where tremendous challenges exist in the design of the <strong>4D</strong> <strong>rotation</strong>, <strong>slicing</strong>, as well as the <strong>joint spatial-temporal optimization scheme</strong>. <span style = "color: blue;"><strong>We draw inspiration from geometric algebra and carefully choose 4D rotor to represent 4D rotation, which is a spatial-temporal separable rotation representation</strong></span>. Notably, rotor representation accommodates both 3D and 4D rotation: when the temporal dimension is set to zero, it becomes equivalent to a quaternion and can represent 3D spatial rotation as well. Such adaptability grants our method the flexibility to model both dynamic and static scenes. In other words, 4DGS is a generalizable form of 3DGS: <strong>when closing the temporal dimension, our 4DGS reduces to 3DGS</strong>. </p>
<p><span style = "color: blue;"> <strong>We enhance the optimization strategies in 3DGS and introduce two new regularization terms to stabilize and improve the dynamic reconstruction</strong></span>.We first propose an <strong>entropy loss</strong> that pushes the opacity of Gaussians towards either one or zero, which proves effective to remove “floaters” in our experiments. We further introduce a novel <strong>4D consistency loss</strong> to regularize the motion of Gaussian points and yield more consistent dynamics reconstruction. Experiments show that both terms notably improve the rendering quality. </p>
<p>While existing Gaussian-based methods are mostly based on PyTorch, we further develop a highly optimized CUDA framework with careful engineering designs for fast training and inference speed. Our framework supports rendering 1352×1014 videos at an unprecedented 583 FPS on an RTX 4090 GPU and 277 FPS on an RTX 3090 GPU. We conduct extensive experiments on two datasets spanning a wide range of settings and motion patterns, including monocular videos and multicamera videos. Quantitative and qualitative evaluations demonstrate the distinct advantages over preceding methods, including the new state-of-the-art rendering quality and speed.</p>
<h1 id="4D-Gaussian-Splatting-for-Real-Time-Dynamic-Scene-Rendering"><a href="#4D-Gaussian-Splatting-for-Real-Time-Dynamic-Scene-Rendering" class="headerlink" title="4D Gaussian Splatting for Real-Time Dynamic Scene Rendering"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.08528">4D Gaussian Splatting for Real-Time Dynamic Scene Rendering</a></h1><ul>
<li>7 Dec 2023</li>
</ul>
<h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><p>Representing and rendering dynamic scenes has been an important but challenging task. Especially, to accurately model complex motions, high efficiency is usually hard to guarantee. <strong>To achieve real-time dynamic scene rendering while also enjoying high training and storage efficiency</strong>, we propose <span style ="color:blue;"><strong>4D Gaussian Splatting</strong></span> (4D-GS) as a holistic representation for dynamic scenes rather than applying 3D-GS for each individual frame. </p>
<ul>
<li>In 4D-GS, a novel explicit representation containing both 3D Gaussians and 4D neural voxels is proposed. </li>
<li>A decomposed neural voxel encoding algorithm inspired by HexPlane is proposed to efficiently build Gaussian features from 4D neural voxels and then a lightweight MLP is applied to predict Gaussian deformations at novel timestamps.</li>
<li>Our 4D-GS method achieves real-time rendering under high resolutions, 82 FPS at an 800×800 resolution on an RTX 3090 GPU while maintaining comparable or better quality than previous state-of-the-art methods. More demos and code are available at <a target="_blank" rel="noopener" href="https://guanjunwu.github.io/4dgs/">https://guanjunwu.github.io/4dgs/</a>.</li>
</ul>
<h2 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h2><p>Novel view synthesis (NVS) stands as a critical task in the domain of 3D vision and plays a vital role in many applications, e.g. VR, AR, and movie production. NVS aims at rendering images from any desired viewpoint or timestamp of a scene, usually requiring modeling the scene accurately from several 2D images. Dynamic scenes are quite common in real scenarios, rendering which is important but challenging as <span style ="color:red;"><strong>complex motions need to be modeled with both spatially and temporally sparse input</strong></span>. </p>
<p><strong>NeRF</strong> has achieved great success in synthesizing novel view images by representing scenes with implicit functions. The volume rendering techniques are introduced to connect 2D images and 3D scenes. However, the original NeRF method bears big training and rendering costs. Though some NeRF variants reduce the training time from days to minutes, the rendering process still bears a <span style ="color:red;"><strong>non-negligible latency</strong></span>.</p>
<p>Recent <strong>3D Gaussian Splatting</strong> (3D-GS) significantly boosts the rendering speed to a real-time level by representing the scene as 3D Gaussians. The cumbersome volume rendering in the original NeRF is replaced with efficient differentiable splatting, which directly projects 3D Gaussian points onto the 2D plane. <strong>3D-GS not only enjoys real-time rendering speed but also represents the scene more explicitly, making it easier to manipulate the scene representation.</strong></p>
<p><strong>However, 3D-GS focuses on the static scenes. Extending it to dynamic scenes as a 4D representation is a reasonable, important but difficult topic.</strong> <span style ="color: red;">**The key challenge lies in modeling complicated point motions from sparse input.</span><strong> 3DGS holds a natural geometry prior by representing scenes with point-like Gaussians. One direct and effective extension approach is to </strong>construct 3D Gaussians at each timestamp<strong> but <span style="color:red;"></strong>the storage/memory cost will multiply especially for long input sequences<strong>&lt;/span&gt;. Our goal is to construct a </strong>compact representation while maintaining both training and rendering efficiency<strong>, i.e. <span style="color:blue"></strong>4D Gaussian Splatting (4DGS)**&lt;/span&gt;. </p>
<ul>
<li>To this end, we propose to represent Gaussian motions and shape changes by an efficient <strong>Gaussian deformation field network</strong>, containing a <strong>temporal-spatial structure encoder</strong> and an extremely tiny <strong>multi-head Gaussian deformation decoder</strong>. </li>
<li><strong>Only one set of canonical 3D Gaussians</strong> is maintained. </li>
<li>For each timestamp, the <strong>canonical 3D Gaussians</strong> will be transformed by the <strong>Gaussian deformation field</strong> into new positions with new shapes. The <strong>transformation</strong> process represents both the Gaussian <strong>motion</strong> and <strong>deformation</strong>. </li>
<li>Note that different from modeling motions of each Gaussian separately, the spatial-temporal structure encoder can connect different <strong>adjacent</strong> 3D Gaussians to predict <strong>more accurate motions and shape deformation</strong>. Then the deformed 3D Gaussians can be directly splatted for rendering the according-timestamp image.</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://dianlisan.github.io">Wang Longan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://dianlisan.github.io/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/">https://dianlisan.github.io/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Papers/">Papers</a></div><div class="post_share"><div class="social-share" data-image="/img/self.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2024/06/02/start/" title="This is the Start of My Blog"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">This is the Start of My Blog</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/self.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Wang Longan</div><div class="author-info__description">Exchanging Hope for Thoughts and Insights</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/LonganWANG-cs"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/LonganWANG-cs" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:wanglongan1007@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Exchanging hope for thoughts and insights!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Motion-aware-3D-Gaussian-Splatting-for-Efficient-Dynamic-Scene-Reconstruction"><span class="toc-number">1.</span> <span class="toc-text">Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">1.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.2.</span> <span class="toc-text">Introduction</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4D-Gaussian-Splatting-Towards-Efficient-Novel-View-Synthesis-for-Dynamic-Scenes"><span class="toc-number">2.</span> <span class="toc-text">4D Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract-1"><span class="toc-number">2.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction-1"><span class="toc-number">2.2.</span> <span class="toc-text">Introduction</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4D-Gaussian-Splatting-for-Real-Time-Dynamic-Scene-Rendering"><span class="toc-number">3.</span> <span class="toc-text">4D Gaussian Splatting for Real-Time Dynamic Scene Rendering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract-2"><span class="toc-number">3.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction-2"><span class="toc-number">3.2.</span> <span class="toc-text">Introduction</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/" title="Papers about Dynamic Gaussian Splatting">Papers about Dynamic Gaussian Splatting</a><time datetime="2024-06-24T08:03:34.000Z" title="Created 2024-06-24 16:03:34">2024-06-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/02/start/" title="This is the Start of My Blog">This is the Start of My Blog</a><time datetime="2024-06-02T08:03:34.000Z" title="Created 2024-06-02 16:03:34">2024-06-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/06/02/hello-world/" title="Hello World">Hello World</a><time datetime="2024-06-02T04:07:30.672Z" title="Created 2024-06-02 12:07:30">2024-06-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By Wang Longan</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Come to pwn me!!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>