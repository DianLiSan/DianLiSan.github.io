<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Papers about Dynamic Gaussian Splatting</title>
      <link href="/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/"/>
      <url>/2024/06/24/Papers-about-Dynamic-Gaussian-Splatting/</url>
      
        <content type="html"><![CDATA[<h1 id="Motion-aware-3D-Gaussian-Splatting-for-Efficient-Dynamic-Scene-Reconstruction"><a href="#Motion-aware-3D-Gaussian-Splatting-for-Efficient-Dynamic-Scene-Reconstruction" class="headerlink" title="Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction"></a><a href="https://arxiv.org/abs/2403.11447">Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction</a></h1><ul><li>18 Mar 2024</li></ul><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>3D Gaussian Splatting (3DGS) has become an emerging tool for dynamic scene reconstruction. However, existing methods focus mainly on extending static 3DGS into a time-variant representation, <span style="color: red;"><strong>while overlooking the rich motion information carried by 2D observations</strong></span>, thus suffering from performance degradation and model redundancy. To address the above problem, we propose a novel <span style="color: blue;"><strong>motion-aware</strong></span> enhancement framework for dynamic scene reconstruction, which mines useful motion cues from optical flow to improve different paradigms of dynamic 3DGS.</p><ul><li>Specifically, we first establish a <strong>correspondence between 3D Gaussian movements and pixel-level flow</strong>.</li><li>Then a novel <strong>flow augmentation</strong> method is introduced with additional insights into <strong>uncertainty</strong> and <strong>loss collaboration</strong>.</li><li>Moreover, for the prevalent <strong>deformation-based</strong> paradigm that presents a harder optimization problem, a <strong>transient-aware deformation auxiliary module is proposed</strong>. </li><li>We conduct extensive experiments on both multi-view and monocular scenes to verify the merits of our work. Compared with the baselines, our method shows significant superiority in both rendering quality and efficiency.</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>While static scene modeling has witnessed significant progress in recent years, <strong>reconstructing dynamic scenes</strong> remains an intractable challenge due to the difficulties introduced by <span style="color: red;"><strong>motion complexities, topological changes, and spatially or temporally sparse observations</strong></span>.</p><p>In the past few years, <strong>Neural Radiance Fields</strong> (NeRF) has emerged as a remarkable implicit representation for 3D scenes. Despite their impressive visual quality, <span style="color: red;"><strong>the large time overhead stands as a non-negligible obstacle to their practical application</strong></span>. Recently, a new method named <strong>3D Gaussian Splatting</strong> (3DGS) has attracted substantial attention from the research community. 3DGS gets rid of the expensive deep neural networks and ray-tracing rendering of NeRF-based methods by introducing the explicit 3D Gaussian representation and efficient point-based rasterization. As a strong competitor to NeRF, 3DGS achieves comparable performance in novel view synthesis while <span style="color: blue;"> <strong>boosting the rendering speed to a real-time level</strong> </span>.</p><p><strong>It is then a straightforward but challenging task to extend the static 3DGS to a time-variant representation for dynamic content.</strong> Some pioneers have tried different strategies, e.g., <strong>iteration</strong> or <strong>deformation</strong>, to address this problem. However, these 3DGS-based works typically focus on the design of dynamic modeling. They regard frames as discrete samples to fit time-dependent trajectories or deformations, <span style = "color: red;"><strong>while overlooking the rich motion cues underneath sequential 2D observations</strong></span>. Since dynamic 3DGS involves explicit moving and deforming of Gaussians, it presents a tough <span style = "color: red;"><strong>under-constrained problem</strong></span> to use only images to supervise the reconstruction. <strong>The model is prone to local optimum where temporal consistency of Gaussians is not maintained as in physical world, especially for cases with insufficient viewpoints.</strong> This leads to visual overfitting, performance degradation, and redundant modeling in practice.</p><p><strong>To address the above issues, we propose a novel motion-aware framework to enhance dynamic 3DGS by taking full advantage of optical flow prior.</strong> </p><ul><li>As a well-explored representation of pixel-level movement, <span style = "color: blue;"><strong>optical flow can be efficiently predicted by pretrained networks</strong></span>, providing low-cost 2D motion prior for 3DGS. </li><li>Instead of using plausible render-based supervision like previous practices in depth or segmentation, we propose to establish a more robust and finer-grained cross-dimensional motion correspondence specially designed for flows. In this way, <span style = "color: blue;"><strong>Gaussian motions between frames can be aligned with 2D prior using our uncertainty-aware flow loss</strong>.</span></li><li>Meanwhile, We offer <span style = "color: blue;"> <strong>dynamic awareness to existing regularization in neural rendering with the help of flow prior</strong></span>, thereby giving special attention to the motion parts during optimization.</li><li>Moreover, the prevalent deformation-based paradigm for dynamic 3DGS is susceptible to 3D motion ambiguities when relying solely on relative flow constraints. Therefore, we propose an additional <span style = "color: blue;"> <strong>deformation auxiliary module to inject transient motion information into Gaussian features and improve the dynamic modeling</strong></span>.</li><li>The overall framework is proved by extensive experiments to be an effective enhancing solution for multi-view/monocular scenes, which possesses efficient dynamic modeling capabilities with less redundancy.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Dynamic Gaussian Splatting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Papers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>This is the Start of My Blog</title>
      <link href="/2024/06/02/start/"/>
      <url>/2024/06/02/start/</url>
      
        <content type="html"><![CDATA[<p>Welcome to my blog! Maybe we should call it the Progress Report.</p><p>As you can see, I’m not particularly skilled at writing in English. Yet, I’ve decided to document the little things in my life in English. Here are some reasons why:</p><p>This blog, along with future ones, is meant to be a tool for practicing English. It’s also a progress report on my English writing skills. Inspired by ``Flowers for Algernon’’, I believe that the evolution of my language and writing will reflect changes in my mental state and cognitive abilities, which should be quite fascinating. Because writing in English forces me to focus on the clarity and logical structure of my sentences rather than on elegant phrasing. Through this straightforward but challenging method, I hope to concentrate more on my thoughts about life and better understand the changes in my psychological state.</p><p>Often, when we are eager to achieve something or reach a certain mental state, we might end up doing the opposite. This idea is presented in ``The Glass Bead Game’’, where the music master advises the protagonist to take time for meditation to get out of this situation. However, given my understanding of my own intellectual capabilities, meditation doesn’t seem a very practical solution for me. My mind is not able to handle multiple things in a multi-threaded manner, and it is also difficult for me to focus on a single task for a long time. I often blur or even forget my previous insights after a lot of thinking. Therefore, why not record some of these thoughts and insights instead of just leaving them in the brain? Not only will this help clarify my current reality, but it will also serve as valuable material for future self-reflection. As mentioned earlier, this provides excellent feedback on my cognitive development and its evolution.</p><p>To better achieve this goal, I plan to conduct a weekly summary. Regular self-examination will help me understand how my psychological state evolves over different periods and the impact of continuous time sequences on my thoughts. Whether I can stick to this schedule remains to be seen.</p><p>At this stage, my work is becoming increasingly busy. I’m unsure how current events will unfold in the future. This includes a paper I’m submitting, my new advisor at NUS, my completely new research direction, and the development of relationships with new acquaintances. All these stem from my bold decision to abandon my guaranteed postgraduate spot and pursue overseas studies—a choice not many have made, offering few precedents. The past years’ pandemic effects and changing international dynamics further obscure my decisions’ future outcomes, making it hard to calculate the probability of achieving my planned goals. The world is complex, like the veil of Maya, obscuring our vision and understanding. We can’t see the true nature of the world, just as a sandy ground in the sunlight looks like water from afar. This uncertainty brings me anxiety. I know that excessive worry about the future isn’t beneficial, but not worrying makes me fear missing opportunities. I realize I might be exaggerating; perhaps these are just trivial matters. Ultimately, I can’t predict the future, but I can only try to minimize potential risks. This state is exhausting, but viewed differently, it’s a trade of hope for what I aim to achieve. I hope it will broaden my perspective, though it might also lead to stressful situations. Maybe this blog will help.</p><p>Years from now, when I look back at this blog, I’ll probably laugh. I hope so—that would mean I’ve made progress. And that’s precisely the purpose of these blogs.</p><p>如你所见，我并不是很擅长英语写作。但我还是决定以英语为主来记录生活中的一些琐事。为什么呢？原因如下：</p><p>这个博客，包括未来的博客，可以作为一种英语练习工具，也可以看作是我英语写作进步的记录。这灵感来自于《献给阿尔吉侬的花束》。通过文字的变化，反映出写作技巧和精神状态、思想认知水平的变化，这应该会非常有趣。</p><p>写英语能让我更加关注句子的表意和句子之间的逻辑结构，而不是华丽的辞藻。因此，我希望通过这种对我来说并不简单的方式，让我更专注于对生活的思考，并进一步了解自己的心理变化。《玻璃球游戏》中提到，当我们迫切想实现某件事或追求某种心理状态时，往往会适得其反。书中的音乐大师建议主人公花时间冥想，但我知道冥想对我来说并不实际。我的思维无法满足多线程处理多件事情，也同样难以长时间专注于单一任务，常常会在大量思考后模糊甚至遗忘之前的见解。所以，记录一些想法和见解不仅能帮助我理清当前的现实，也是一份未来回顾自己的宝贵材料。这对个人思想认知及其变化是一种很好的反馈。</p><p>为了更好地实现这个目标，通过定期自我审视，理清现实对我在不同时间段产生的心理认知影响，以及连续时间对我思想的作用及其变化，我觉得每周至少做一次总结是一个不错的方式。但谁知道我能否坚持呢？</p><p>现阶段工作越来越忙，我也不清楚未来会如何演变。这包括我的一篇在投论文、新加坡国立大学的新导师、全新的研究方向（之前没有任何基础的研究方向），以及新认识的人的关系发展等等。这一切都源于我一个大胆的决定：在保研之前放弃保研，转而出国留学。之前并没有很多人这样做，这样的决策参考实例很少，再加上疫情影响和国际局势的变化，我无法对自己的决定做出清晰的未来预测，也导致我期望的规划完成概率难以计算。世界如此复杂，就像摩耶之纱蒙住我们的双眼，我们无法清晰认识世界的本质。就像阳光下的沙地，远看像水，我们无法看透。这带给我焦虑，但我知道过分担忧未来并不好，但如果不焦虑，我又害怕会错过时机。</p><p>可能说得有些大了，也许这些都是些芝麻大的小事也说不定。总之，我无法预测未来，但我只能尽量降低潜在风险，这样的状态很累。但从另一个角度看，这是一种用希望做交易的方式。我期待这能换来更多的思想与认识，也许这会让我看得更远一些，但同时也可能因为急切与忙碌陷入困境。希望博客能帮上忙。</p><p>多年以后，当我回头看这篇博客时，一定会笑出来的。但愿如此，这也是我进步的反馈，这正是这些博客的初衷。</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/06/02/hello-world/"/>
      <url>/2024/06/02/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> Tech </category>
          
          <category> Website </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
